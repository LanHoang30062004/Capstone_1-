import React, { useRef, useState, useEffect } from "react";
import Webcam from "react-webcam";
import axios from "axios";
import { Button, Space } from "antd";
import "./WebcamVideo.scss";
import vision from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3";
import { toast } from "react-toastify";
import "react-toastify/dist/ReactToastify.css";

const { HandLandmarker, FaceLandmarker, FilesetResolver, DrawingUtils } =
  vision;

const WebcamVideo = ({ word, setAccuracy, setPredicWord }) => {
  const webcamRef = useRef(null);
  const canvasRef = useRef(null);

  const [handLandmarker, setHandLandmarker] = useState(null);
  const [faceLandmarker, setFaceLandmarker] = useState(null);
  const [capturing, setCapturing] = useState(false);
  const [faceCount, setFaceCount] = useState(0);

  const handRef = useRef([]);
  const faceRef = useRef([]);
  const faceResultsRef = useRef(null); // TH√äM: L∆∞u to√†n b·ªô face results

  useEffect(() => {
    const initModels = async () => {
      const filesetResolver = await FilesetResolver.forVisionTasks(
        "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm"
      );

      const handLm = await HandLandmarker.createFromOptions(filesetResolver, {
        baseOptions: {
          modelAssetPath:
            "https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task",
          delegate: "GPU",
        },
        runningMode: "VIDEO",
        numHands: 2,
      });

      const faceLm = await FaceLandmarker.createFromOptions(filesetResolver, {
        baseOptions: {
          modelAssetPath:
            "https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task",
          delegate: "GPU",
        },
        runningMode: "VIDEO",
        outputFaceBlendshapes: false,
        numFaces: 2, // THAY ƒê·ªîI: Cho ph√©p ph√°t hi·ªán t·ªëi ƒëa 2 m·∫∑t
      });

      setHandLandmarker(handLm);
      setFaceLandmarker(faceLm);
    };

    initModels();
  }, []);

  useEffect(() => {
    let lastVideoTime = -1;
    let animationId;

    const predictWebcam = async () => {
      if (
        !webcamRef.current ||
        !webcamRef.current.video ||
        !handLandmarker ||
        !faceLandmarker
      ) {
        animationId = requestAnimationFrame(predictWebcam);
        return;
      }

      const video = webcamRef.current.video;
      const canvas = canvasRef.current;
      const ctx = canvas.getContext("2d");
      const drawingUtils = new DrawingUtils(ctx);

      if (
        video.videoWidth === 0 ||
        video.videoHeight === 0 ||
        video.readyState < 2
      ) {
        animationId = requestAnimationFrame(predictWebcam);
        return;
      }

      if (video.currentTime === lastVideoTime) {
        animationId = requestAnimationFrame(predictWebcam);
        return;
      }
      lastVideoTime = video.currentTime;

      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;

      const timestamp = performance.now();
      const handResult = handLandmarker.detectForVideo(video, timestamp);
      const faceResult = faceLandmarker.detectForVideo(video, timestamp);

      // TH√äM: C·∫≠p nh·∫≠t s·ªë l∆∞·ª£ng m·∫∑t ph√°t hi·ªán
      const currentFaceCount = faceResult.faceLandmarks
        ? faceResult.faceLandmarks.length
        : 0;
      setFaceCount(currentFaceCount);
      faceResultsRef.current = faceResult; // L∆∞u l·∫°i ƒë·ªÉ s·ª≠ d·ª•ng trong startCapture

      ctx.save();
      ctx.clearRect(0, 0, canvas.width, canvas.height);

      /** ---------------- HANDS ---------------- */
      if (handResult.landmarks && handResult.landmarks.length > 0) {
        const hands = [];
        for (let i = 0; i < handResult.landmarks.length; i++) {
          const landmarks = handResult.landmarks[i];

          // Draw connections
          drawingUtils.drawConnectors(
            landmarks,
            HandLandmarker.HAND_CONNECTIONS,
            {
              color: "#ff0000",
              lineWidth: 2,
            }
          );

          // Draw landmarks
          drawingUtils.drawLandmarks(landmarks, {
            color: "#00ff00",
            lineWidth: 2,
          });

          hands.push({
            handedness: handResult.handednesses[i][0].categoryName,
            landmarks,
          });
        }
        handRef.current = hands;
      } else {
        handRef.current = [];
      }

      /** ---------------- FACE ---------------- */
      if (faceResult.faceLandmarks && faceResult.faceLandmarks.length > 0) {
        faceRef.current = faceResult.faceLandmarks[0]; // ch·ªâ l∆∞u ƒë·ªÉ predict
      } else {
        faceRef.current = [];
      }

      ctx.restore();
      animationId = requestAnimationFrame(predictWebcam);
    };

    animationId = requestAnimationFrame(predictWebcam);
    return () => cancelAnimationFrame(animationId);
  }, [handLandmarker, faceLandmarker]);

  const startCapture = () => {
    if (!webcamRef.current) return;

    // TH√äM: Ki·ªÉm tra s·ªë l∆∞·ª£ng m·∫∑t tr∆∞·ªõc khi quay
    if (faceCount > 1) {
      toast.warning(
        `Ph√°t hi·ªán ${faceCount} m·∫∑t trong khung h√¨nh! H√£y ƒë·∫£m b·∫£o ch·ªâ c√≥ 1 m·∫∑t ƒë·ªÉ k·∫øt qu·∫£ ch√≠nh x√°c.`,
        {
          position: "top-right",
          autoClose: 5000,
          hideProgressBar: false,
          closeOnClick: true,
          pauseOnHover: true,
          draggable: true,
        }
      );
      return; // D·ª™NG L·∫†I n·∫øu c√≥ nhi·ªÅu h∆°n 1 m·∫∑t
    }

    if (faceCount === 0) {
      toast.error("Kh√¥ng ph√°t hi·ªán m·∫∑t n√†o! H√£y ƒëi·ªÅu ch·ªânh v·ªã tr√≠.", {
        position: "top-right",
        autoClose: 3000,
      });
      return;
    }

    setCapturing(true);

    // ‚≠ê TH√äM: Toast th√¥ng b√°o b·∫Øt ƒë·∫ßu quay
    toast.info("üì∏ ƒêang quay video trong 5 gi√¢y...", {
      position: "top-right",
      autoClose: 3000,
    });

    setTimeout(async () => {
      setCapturing(false);

      const video = webcamRef.current.video;

      // TH√äM DEBUG CHI TI·∫æT
      console.log("üîç DEBUG FACE LANDMARKS:");
      console.log(
        `   S·ªë l∆∞·ª£ng face landmarks: ${faceRef.current?.length || 0}`
      );
      console.log(
        `   S·ªë l∆∞·ª£ng hand landmarks: ${handRef.current?.length || 0}`
      );
      console.log(`   S·ªë l∆∞·ª£ng m·∫∑t ph√°t hi·ªán: ${faceCount}`);

      if (faceRef.current && faceRef.current.length > 0) {
        console.log(`   Face landmark ƒë·∫ßu ti√™n:`, faceRef.current[0]);
      }

      // ‚≠ê FIX: TH√äM FACE LANDMARKS
      const payload = {
        word: word || "",
        face_landmarks: (faceRef.current || []).slice(0, 468).map((lm) => ({
          x: lm.x,
          y: lm.y,
        })),
        hand_landmarks: (handRef.current || []).map((h) => ({
          handedness: h.handedness,
          landmarks: (h.landmarks || []).slice(0, 21).map((lm) => ({
            x: lm.x,
            y: lm.y,
          })),
        })),
      };

      console.log("Payload g·ª≠i ƒë·∫øn BE:", {
        word: payload.word,
        face_landmarks_count: payload.face_landmarks.length,
        hand_landmarks_count: payload.hand_landmarks.length,
        sample_hand_landmark: payload.hand_landmarks[0]?.landmarks[0],
      });

      console.log("FIXED Payload:", {
        word: payload.word,
        face_landmarks_count: payload.face_landmarks.length,
        hand_landmarks_count: payload.hand_landmarks.length,
        handedness: payload.hand_landmarks.map((h) => h.handedness),
      });

      try {
        const res = await axios.post(
          "http://localhost:8001/predict-improved",
          payload
        );
        setAccuracy(res.data.confidence);
        setPredicWord(res.data.predicted_word);

        console.log("K·∫øt qu·∫£ t·ª´ BE:", res.data);
      } catch (err) {
        console.error("L·ªói khi g·ª≠i request:", err);
        toast.error("L·ªói k·∫øt n·ªëi ƒë·∫øn server!", {
          position: "top-right",
          autoClose: 3000,
        });
      }
    }, 5000);
  };

  return (
    <div className="webcam">
      <Space direction="vertical" style={{ width: "100%" }}>
        <div style={{ position: "relative" }}>
          <Webcam
            ref={webcamRef}
            mirrored={true}
            videoConstraints={{ facingMode: "user" }}
            style={{
              width: "100%",
              height: "100%",
              borderRadius: "10px",
              transform: "scaleX(-1)",
            }}
          />

          <canvas
            ref={canvasRef}
            style={{
              position: "absolute",
              left: 0,
              top: 0,
              width: "100%",
              height: "100%",
              pointerEvents: "none",
              // visibility: "hidden",
            }}
          />
        </div>

        <Button
          type="primary"
          onClick={startCapture}
          disabled={!handLandmarker || !faceLandmarker || capturing}
          block
          size="large"
          style={{
            backgroundColor: faceCount > 1 ? "#ff4d4f" : "#49BBBD",
          }}
        >
          {capturing ? "ƒêang quay..." : "Quay & Predict"}
        </Button>
      </Space>
    </div>
  );
};

export default WebcamVideo;
